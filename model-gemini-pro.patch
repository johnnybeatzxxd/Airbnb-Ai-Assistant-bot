From a6dcffa26587d634201890669130ea5b5d2ee5ae Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Fri, 16 Feb 2024 13:51:53 +0300
Subject: [PATCH 01/11] gemini pro api key added to .env

---
 .env | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/.env b/.env
index b6a4b3d..da1c328 100644
--- a/.env
+++ b/.env
@@ -1,3 +1,4 @@
 MongoConnection=YOUR_MONGODB_CONNECTION_URL
 OpenAiKey=YOUR_OPENAI_API_KEY
-TelegramBotToken=YOUR_TELEGRAM_BOT_TOKEN
\ No newline at end of file
+TelegramBotToken=YOUR_TELEGRAM_BOT_TOKEN
+GeminiProKey=YOUR_GEMINI_PRO_API_KEY
\ No newline at end of file
-- 
2.43.0.windows.1


From a4a84d59824dce8dfea0b96e9e290c0217145e07 Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Fri, 16 Feb 2024 13:59:16 +0300
Subject: [PATCH 02/11] openai package replaced by googles package

---
 requirements.txt | Bin 484 -> 1808 bytes
 1 file changed, 0 insertions(+), 0 deletions(-)

diff --git a/requirements.txt b/requirements.txt
index a6af4900857e8462b2a56d6d9f4bd30a9cefdd5c..cb97181bd9082fa85da7e31e8d93feb8fffb780f 100644
GIT binary patch
literal 1808
zcmZuyO>fgs5Zp5oKgCh)w1FNtfVgnuz`b(qw0Xs`gY8reKOUIb@ymNbQIyY}-JPBN
z$lpJ;1siN<Gad)~gvZ)ec8}-U-rGBqeFEy)dVK2~Q@VX+<$~#98xWz!b8D>?ct0WD
z)+Wc_0KdWW=8QjiUgo>S?^R}-kSW**-zWDapAU`^A2J=6xRtX_-VGQusAdbyfJe9B
z?%>ZjmFI6@AAtzS5Ijc(X4RQVMC}lbnHa6`3P;<!2El%NjHp*0n^_0=)s7{C)w9Zt
zXK#^n@)`!uO)aUnwE1c;@a&<1tYl7qacW_ipz8_#J0SXn{mO)+LQlv&IKLiDl#48w
zhb+`H#vhQSLmdS&2E0DwbMJMrkHKE?xm(yA@lJbQj~M?S>EN*%L}w3)XMalX;q}}{
zuO=cZ`w0BC*w^@xdE}J3kaMb`7gZ=Q83TH<$7_#o2iJ*nq8X(=8|NBxkH9qWO?}#U
zFJcwRUU)~T+VLV9I~UPMWDU+?Jok+`)Aa6uEzi}I-Ys#7`<bgs-!vH!@pksFvW*Ma
zNp3HdqDq>?fZsTY-0I7{zVk`lqngeqfiv6S6aBTvoH$O~0F5{`c^~o)9$;zgCtkVL
zoNM(t^(ys&J?SnK)P75YgnI-=w?Vf<+f6pyj2bodnU1uo2f4NIIcUAY{7R8m%y)un
z+(qs}v+&j(OYw5V!_wV+>Zz7?m)SLYakq67a&|v_<F-&q_u~uno$a%Iw{M<b`^$=M
zUH$wL6ktm<yYcGiI3Z%oZTy9LS?#<`DQ9mDbz;rDcA64qy7wGZlb4dWGHpWAX+qQv
z%Ewz7w~-OVat5MB?X;+7sv=hUpU`AHfZN+r0snEhr`k=ii7aPaH|oyG)im*XlacZr
Zp&lnX*du-wBHuI42obcfc3xk3{sS^h2{8Zw

literal 484
zcmX|8F>=Eo5bXJj83D4A6cov%NtYtMhX^DQqXWY^WBK*DlV?&cx9sliIe?4~gFoO_
zLbJA$gY1NZEoN(bsTs66)-YLX<df853>D)Pt<{}o0=+D*wtxr7b#*D;LuIbvNlv-C
z)v<0b2jOGGO2SIMknsDDgPG7#cEt72%7#k@QkL{2<}1W8SH@}&vM9wus;A+CSZEkn
zi+?k|@l<pE=z%;9IYwycQev8sN0CbaN7;$@EQ%Y?ZjLaM1E(#UcYtx^0E1Nj`1CN+
zQVlz6&3kNGXeWJz6lU7;E#vFw2e+n<vZvp?%)w_2@cW3VL=Bf~Xh=nCX(+j95T}W|
z=6nP%sc@N(!g_%hzp~=MR&*i?dkQyFY%v3=^m~zb_YP@cx`-j?YfUMB8}{J){Q)?b
Bky-!%

-- 
2.43.0.windows.1


From e19f65b7e05dab80c89c1d89d44ef069f85f453f Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Sat, 17 Feb 2024 14:49:20 +0300
Subject: [PATCH 03/11] OpenAI api replaced with Gemini api in
 generate_response function

---
 Assistant/ai.py | 87 ++++++++++++++++++++++++++++---------------------
 1 file changed, 50 insertions(+), 37 deletions(-)

diff --git a/Assistant/ai.py b/Assistant/ai.py
index 4d0db85..365d7cd 100644
--- a/Assistant/ai.py
+++ b/Assistant/ai.py
@@ -4,12 +4,15 @@ from . import database
 from . import airbnb
 import datetime
 import time
-import openai
+import requests
 import os
 from dotenv import load_dotenv
 load_dotenv()
 
-openai.api_key = os.environ.get('OpenAiKey')
+gemini_api_key = os.environ.get('GeminiProKey')
+url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={}".format(gemini_api_key)
+headers = {"Content-Type": "application/json",}
+
 
 today = datetime.date.today()
 year = today.year
@@ -67,7 +70,7 @@ function_descriptions = [
                 },
                 "required": ["image_of"],
             }
-            },
+        },
         
         
         
@@ -207,50 +210,60 @@ class llm:
 
     def generate_response(self,_id,messages,required_user_info,):
     
+        data = {
+                "contents": [messages],
+                "tools": [{
+                    "functionDeclarations": self.function_descriptions
+                    }]
+                }
+
         print("generating answer ... ")
         while True:
             try:
-                response = openai.ChatCompletion.create( 
-                    model="gpt-3.5-turbo-1106",
-                    messages=messages,
-                    functions = self.function_descriptions,
-                    function_call="auto",
-                    temperature = 0.9
-                )
-                break
-            except openai.error.RateLimitError:
+                response = requests.post(url, headers=headers, json=data)
+                if response.status_code == 200:
+                    break
+            except:
                 print('limit exception...')
-                time.sleep(20)
-        print(response["choices"][0]["message"])
-        while response["choices"][0]["finish_reason"] == "function_call":
+                time.sleep(3)
+        print(response["candidates"][0]["content"]["parts"])
+        while "functionCall" in response["candidates"][0]["content"]["parts"][0]:
+
+            function_call = response["candidates"][0]["content"]["parts"][0]["functionCall"]
+            function_name = function_call["name"]
 
             function_response = self.function_call(response,_id)
             #bot.send_chat_action(tg.chat.id, 'typing')
+
             result = json.dumps(function_response)
             messages.append({
-                "role": "function",
-                "name": response["choices"][0]["message"]["function_call"]["name"],
-                "content": response["choices"][0]["message"]["function_call"]['arguments']
-            })
-            messages.append({
-                "role": "function",
-                "name": response["choices"][0]["message"]["function_call"]["name"],
-                "content": function_response
-            })
-            #print(messages)
+                            "role": "model",
+                            "parts":[{
+                              "functionCall": {
+                              "name": function_name,
+                              "args": function_call["args"]
+                                                }             
+                                    }]
+                            },)
+            messages.append({"role": "function",
+                            "parts":[{
+                                "functionResponse":{
+                                    "name": function_name,
+                                    "response":{
+                                        "name": function_name,
+                                        "content": function_response
+                                                }
+                                                    }  
+                                    }]
+                            })
+            
             while True:
                 try:
-                    response = openai.ChatCompletion.create( 
-                        model="gpt-3.5-turbo-1106",
-                        messages=messages,
-                        functions = self.function_descriptions,
-                        function_call="auto",
-                        temperature = 0.9
-                    )
-                    break
-                except openai.error.RateLimitError:
+                    response = requests.post(url, headers=headers, json=data)
+                    if response.status_code == 200:
+                        break
+                except:
                     print('limit exception...')
-                    time.sleep(20)
-
+                    time.sleep()
                #print(response["choices"][0]["message"])
-        return response["choices"][0]["message"]["content"]
+        return response["candidates"][0]["content"]["parts"][0]["text"]
-- 
2.43.0.windows.1


From 9feed2b488c2ea07cc54c58c81219c1f632ad376 Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Sat, 17 Feb 2024 14:52:32 +0300
Subject: [PATCH 04/11] Update API keys and adjust function call parsing in
 function_call function.

---
 Assistant/ai.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Assistant/ai.py b/Assistant/ai.py
index 365d7cd..525da59 100644
--- a/Assistant/ai.py
+++ b/Assistant/ai.py
@@ -142,7 +142,7 @@ class llm:
         return random_numbers
     def function_call(self,response,_id):
         
-        function_call = response["choices"][0]["message"]["function_call"]
+        function_call = response["candidates"][0]["content"]["parts"][0]["functionCall"]
         function_name = function_call["name"]
         function_args = json.loads(response["choices"][0]["message"]["function_call"]["arguments"])
 
-- 
2.43.0.windows.1


From b2ba0f33125b730cfe978508a3b1120d0512cb77 Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Sat, 17 Feb 2024 16:10:43 +0300
Subject: [PATCH 05/11] Refactor function parameter names for consistency and
 update API response handling to properly parse JSON data.

---
 Assistant/ai.py | 35 +++++++++++++++++++++--------------
 1 file changed, 21 insertions(+), 14 deletions(-)

diff --git a/Assistant/ai.py b/Assistant/ai.py
index 525da59..e590992 100644
--- a/Assistant/ai.py
+++ b/Assistant/ai.py
@@ -46,7 +46,7 @@ function_descriptions = [
             "parameters": {
                 "type": "object",
                 "properties": {
-                    "off topic": {
+                    "off_topic": {
                         "type": "string",
                         "description": "true or false",
                     }
@@ -80,7 +80,7 @@ function_descriptions = [
             "parameters": {
                 "type": "object",
                 "properties": {
-                    "information needed": {
+                    "information_needed": {
                         "type": "string",
                         "description": "The type of information requested. It must be one of the following: [title,description,price,availability,bedroom,location,rules,Safety & property]. Otherwise, the app will crash.",
                     },               
@@ -144,9 +144,9 @@ class llm:
         
         function_call = response["candidates"][0]["content"]["parts"][0]["functionCall"]
         function_name = function_call["name"]
-        function_args = json.loads(response["choices"][0]["message"]["function_call"]["arguments"])
-
-        with open("properties.json", "r") as f:
+        function_args = function_call["args"]
+        print(type(function_args))
+        with open("AirbnbAssistant\properties.json", "r") as f:
                 properties = json.load(f)
     
         if function_name == "save_user_information":
@@ -164,7 +164,7 @@ class llm:
             return database.set_user_info(_id,info)
     
         if function_name == "get_property_info":
-            arg = function_args["information needed"]
+            arg = function_args["information_needed"]
             if arg == "price":
 
                 price = airbnb.get(query="price")
@@ -211,24 +211,31 @@ class llm:
     def generate_response(self,_id,messages,required_user_info,):
     
         data = {
-                "contents": [messages],
+                "contents": messages,
                 "tools": [{
                     "functionDeclarations": self.function_descriptions
-                    }]
-                }
+                    }],
+                "generationConfig": {
+                "temperature": 0.4,
+                "topK": 1,
+                "topP": 1,
+                "maxOutputTokens": 2048,
+                "stopSequences": []
+              },}
 
         print("generating answer ... ")
         while True:
             try:
                 response = requests.post(url, headers=headers, json=data)
                 if response.status_code == 200:
+                    response = response.json()
                     break
             except:
-                print('limit exception...')
+                print('Error')
                 time.sleep(3)
-        print(response["candidates"][0]["content"]["parts"])
+        
         while "functionCall" in response["candidates"][0]["content"]["parts"][0]:
-
+            
             function_call = response["candidates"][0]["content"]["parts"][0]["functionCall"]
             function_name = function_call["name"]
 
@@ -261,9 +268,9 @@ class llm:
                 try:
                     response = requests.post(url, headers=headers, json=data)
                     if response.status_code == 200:
+                        response = response.json()
                         break
                 except:
-                    print('limit exception...')
+                    print('Error')
                     time.sleep()
-               #print(response["choices"][0]["message"])
         return response["candidates"][0]["content"]["parts"][0]["text"]
-- 
2.43.0.windows.1


From 00993b392b3073c5aa923d7527a04350a41d02fb Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Sat, 17 Feb 2024 16:15:54 +0300
Subject: [PATCH 06/11] Update GeminiProKey in .env

---
 .env | 1 -
 1 file changed, 1 deletion(-)

diff --git a/.env b/.env
index da1c328..f552aa1 100644
--- a/.env
+++ b/.env
@@ -1,4 +1,3 @@
 MongoConnection=YOUR_MONGODB_CONNECTION_URL
-OpenAiKey=YOUR_OPENAI_API_KEY
 TelegramBotToken=YOUR_TELEGRAM_BOT_TOKEN
 GeminiProKey=YOUR_GEMINI_PRO_API_KEY
\ No newline at end of file
-- 
2.43.0.windows.1


From d3b152ec14b80178aa45481f29011a1dd770d98c Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Sat, 17 Feb 2024 16:28:03 +0300
Subject: [PATCH 07/11] Database conversation structure updated

---
 Assistant/database.py | 16 +++++++++-------
 1 file changed, 9 insertions(+), 7 deletions(-)

diff --git a/Assistant/database.py b/Assistant/database.py
index 5ae6a30..05a07e1 100644
--- a/Assistant/database.py
+++ b/Assistant/database.py
@@ -7,35 +7,37 @@ load_dotenv()
 
 client = MongoClient(os.environ.get("MongoConnection"))
 db = client['AirbnbAssistant']
-Users = db['Users']  
+Users = db['GOOGLE']  
 
-instruction = {"role": "system","content": "you are help full assistant. you assist our customers by answering questions about our property we have on airbnb. you only assist users with only our property and business realted question."}
+instruction = "you are help full assistant. you assist our customers by answering questions about our property we have on airbnb. you only assist users with only our property and business realted question."
 
 def reset_conversation(_id):
-    Users.update_one({"_id":int(_id)},{"$set":{"conversation":[instruction]}})
+    Users.update_one({"_id":int(_id)},{"$set":{"conversation":[]}})
 
 def register(_id,first_name,username): 
     existance = Users.find_one({"_id":int(_id)})
     if existance == None:
-        Users.insert_one({"_id":_id,"firstName":first_name,"userName":username,"email":"","personalName":"","conversation":[instruction]})
+        Users.insert_one({"_id":_id,"firstName":first_name,"userName":username,"email":"","personalName":"","conversation":[]})
     
 def add_message(_id,message,role):
     conversation = Users.find_one({"_id":_id}).get("conversation")
-    conversation.append({"role":role,"content":message})
+    conversation.append({"role":role,"parts":[{"text":instruction},{"text":message}]})
     Users.update_one({"_id":int(_id)},{"$set":{"conversation":conversation}})
     return conversation
   
-def required_user_info(_id): # returns user Email and Name
+def required_user_info(_id): 
+    # returns user Email and Name
     required_info = {}
     email = Users.find_one({"_id":_id}).get("email")
     personalName = Users.find_one({"_id":_id}).get("personalName")
     user_info = {"email":email,"personalName":personalName}
     required_info = []
+
     if user_info["email"] == "":
         required_info.append("email")
     if user_info["personalName"] == "":
         required_info.append("personalName")
-    print(required_info)
+    
     return required_info
 
 def set_user_info(_id,info):
-- 
2.43.0.windows.1


From 323809eaba4ced46d49a654cf82f9b207fc53f91 Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Sat, 17 Feb 2024 16:39:04 +0300
Subject: [PATCH 08/11] role name motified

---
 Assistant/views.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Assistant/views.py b/Assistant/views.py
index f463cbd..8d65f1f 100644
--- a/Assistant/views.py
+++ b/Assistant/views.py
@@ -47,7 +47,7 @@ class TelegramWebhookView(View):
             required_user_info = database.required_user_info(id_)
             llm = ai.llm()
             response = llm.generate_response(id_,conversation,required_user_info)
-            database.add_message(id_,response,"assistant")
+            database.add_message(id_,response,"model")
             images = []
             if llm.responseType == 'image':
                 for i in llm.random_imgs:
-- 
2.43.0.windows.1


From 8e1473eaff01a31459c6e967d3ec5e69c28ee687 Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Sat, 17 Feb 2024 17:00:31 +0300
Subject: [PATCH 09/11] redundant 'instruction' field removed

---
 Assistant/database.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Assistant/database.py b/Assistant/database.py
index 05a07e1..f1dec61 100644
--- a/Assistant/database.py
+++ b/Assistant/database.py
@@ -21,7 +21,7 @@ def register(_id,first_name,username):
     
 def add_message(_id,message,role):
     conversation = Users.find_one({"_id":_id}).get("conversation")
-    conversation.append({"role":role,"parts":[{"text":instruction},{"text":message}]})
+    conversation.append({"role":role,"parts":[{"text":message}]})
     Users.update_one({"_id":int(_id)},{"$set":{"conversation":conversation}})
     return conversation
   
-- 
2.43.0.windows.1


From 9d58c04a54af98934f56771e2be8198cb70bed38 Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Sat, 17 Feb 2024 17:07:40 +0300
Subject: [PATCH 10/11] properties.json file relative path fixed

---
 Assistant/ai.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Assistant/ai.py b/Assistant/ai.py
index e590992..b2b27a8 100644
--- a/Assistant/ai.py
+++ b/Assistant/ai.py
@@ -146,7 +146,7 @@ class llm:
         function_name = function_call["name"]
         function_args = function_call["args"]
         print(type(function_args))
-        with open("AirbnbAssistant\properties.json", "r") as f:
+        with open("properties.json", "r") as f:
                 properties = json.load(f)
     
         if function_name == "save_user_information":
-- 
2.43.0.windows.1


From 8830c7eea6c34a786e45aeddfb9cff5b650952b0 Mon Sep 17 00:00:00 2001
From: johnnybeatz <92400293+johnnybeatz@users.noreply.github.com>
Date: Sat, 17 Feb 2024 17:29:47 +0300
Subject: [PATCH 11/11] Refine generationConfig temperature to 0.1

---
 Assistant/ai.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Assistant/ai.py b/Assistant/ai.py
index b2b27a8..4e406ae 100644
--- a/Assistant/ai.py
+++ b/Assistant/ai.py
@@ -216,7 +216,7 @@ class llm:
                     "functionDeclarations": self.function_descriptions
                     }],
                 "generationConfig": {
-                "temperature": 0.4,
+                "temperature": 0.1,
                 "topK": 1,
                 "topP": 1,
                 "maxOutputTokens": 2048,
-- 
2.43.0.windows.1

